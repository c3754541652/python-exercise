{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已获得50个页面链接\n",
      "已获得2487个帖子链接\n",
      "已获得2487个response\n",
      "已获得2473个list\n",
      "本程序共花费1969.724417 s\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from matplotlib.font_manager import FontProperties  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'}\n",
    "\n",
    "#获得页面链接\n",
    "def get_pageurl(page_num):\n",
    "        url = 'http://tieba.baidu.com/f?kw=excel&ie=utf-8&pn='\n",
    "        page_list = []\n",
    "        for i in range(0,page_num*50,50):\n",
    "            page_list.append(url+str(i))    #获得页面（50个）的链接\n",
    "        print('已获得%i个页面链接'%len(page_list))\n",
    "        return page_list\n",
    "\n",
    "#获得每个页面链接中的帖子链接\n",
    "def get_url(page_list):\n",
    "    url_list = []\n",
    "    r = re.compile('<a href=\"(.*?)\" title=\"(.*?)\" target=\"_blank\" class=\"j_th_tit \">.*?</a>')   \n",
    "    #把所有链接全部整合到一个列表中来\n",
    "    for url in page_list:\n",
    "        response = requests.session().get(url,headers=headers).text\n",
    "        soup = BeautifulSoup(response,\"html5lib\")\n",
    "        mo = r.findall(str(soup))\n",
    "        p = 'http://tieba.baidu.com/'\n",
    "        #对每一页主页，都提取出链接\n",
    "        for i in range(len(mo)):\n",
    "            url_list.append(p + mo[i][0])\n",
    "    print('已获得%i个帖子链接'%len(url_list))\n",
    "    return url_list\n",
    "\n",
    "#获得所有的response\n",
    "def get_response(url_list):\n",
    "    response_list = []\n",
    "    for url in url_list:\n",
    "        try:\n",
    "            response = requests.session().get(url,headers=headers).text\n",
    "            response_list.append(response)\n",
    "        except:\n",
    "            continue\n",
    "    print('已获得%i个response'%len(response_list))\n",
    "    return response_list\n",
    "\n",
    "#获得主题\n",
    "def get_list(response_list):\n",
    "    tieba_list = []\n",
    "    for response in response_list:\n",
    "        inner_list = []\n",
    "        try:\n",
    "            soup = BeautifulSoup(response,'lxml')\n",
    "            inner_list.append(soup.h1['title'])\n",
    "            r_1 = re.compile('<div author=(.*?) class=\"louzhubiaoshi j_louzhubiaoshi\">')\n",
    "            inner_list.append(r_1.findall(str(soup))[0])\n",
    "            r_2 = re.compile('\"date\":\"(.*?)\"')\n",
    "            inner_list.append(r_2.findall(str(soup))[0])\n",
    "            tieba_list.append(inner_list)\n",
    "        except:\n",
    "            continue\n",
    "    print('已获得%i个list'%len(tieba_list))\n",
    "    return tieba_list\n",
    "\n",
    "#把主题字符串放在一起\n",
    "def get_jieba(jieba_data):\n",
    "    st = ''\n",
    "    word_list = []\n",
    "    dic = {}\n",
    "    #把主题字符串放在一起\n",
    "    for i in jieba_data['主题']:\n",
    "        st = st + str(i)\n",
    "    seg = jieba.cut(st)\n",
    "    #对字符串进行分词\n",
    "    for word in seg:\n",
    "        word_list.append(word)\n",
    "    #获得TOP20的词语\n",
    "    top_list = jieba.analyse.extract_tags(st, topK=20)\n",
    "    #获得TOP20词语的词频\n",
    "    for item in top_list:\n",
    "        dic[item] = word_list.count(item)\n",
    "    return dic\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = time.clock()     #开始计算时间\n",
    "    page_list = get_pageurl(50)  #获得50页的列表链接\n",
    "    url_list = get_url(page_list)  #获得50页中的所有帖子链接\n",
    "    response_list = get_response(url_list)  #获得所有帖子链接的response\n",
    "    tieba_list =  get_list(response_list)   #获得所有帖子的主题、发帖人和发帖时间\n",
    "    data = pd.DataFrame(tieba_list,columns = ['主题','发帖人','发帖时间'])   \n",
    "    data.to_excel('D:\\\\MyConfiguration\\\\cp14330\\\\Desktop\\\\百度贴吧帖子.xlsx',index = False)   #把数据存储下来\n",
    "    m = get_jieba(data)\n",
    "    #把数据处理到pandas里面\n",
    "    jieba_pd = pd.DataFrame(m,index=[0]).T  \n",
    "    jieba_pd = jieba_pd.reset_index()\n",
    "    jieba_pd = jieba_pd.rename(columns = {0:'频次','index':'主题'})\n",
    "    jieba_pd = jieba_pd.sort(ascending = False,columns = '频次')\n",
    "    #开始用pyplot画图\n",
    "    x = [i for i in jieba_pd['主题']]\n",
    "    y = [i for i in jieba_pd['频次']]\n",
    "    font_set = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=15) \n",
    "    o = [i for i in range(20)]\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.bar(o,y)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(o)  \n",
    "    ax.set_xticklabels(x)  \n",
    "    ax.set_xticklabels(x,fontproperties=font_set)\n",
    "    plt.show\n",
    "    end = time.clock()  #获得程序结束时间\n",
    "    print('本程序共花费%f s' %(end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
